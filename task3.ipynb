{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1dc49f4-d21d-4410-a065-7ac43b0890d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\payal\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\payal\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\payal\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\payal\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\payal\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\payal\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\payal\\anaconda3\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\payal\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\payal\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\payal\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\payal\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\payal\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\payal\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84e9f1fd-7258-4ce7-a27c-9020b55aa441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved the webpage.\n",
      "                                                title  \\\n",
      "0                                A Light in the Attic   \n",
      "1                                  Tipping the Velvet   \n",
      "2                                          Soumission   \n",
      "3                                       Sharp Objects   \n",
      "4               Sapiens: A Brief History of Humankind   \n",
      "5                                     The Requiem Red   \n",
      "6   The Dirty Little Secrets of Getting Your Dream...   \n",
      "7   The Coming Woman: A Novel Based on the Life of...   \n",
      "8   The Boys in the Boat: Nine Americans and Their...   \n",
      "9                                     The Black Maria   \n",
      "10     Starving Hearts (Triangular Trade Trilogy, #1)   \n",
      "11                              Shakespeare's Sonnets   \n",
      "12                                        Set Me Free   \n",
      "13  Scott Pilgrim's Precious Little Life (Scott Pi...   \n",
      "14                          Rip it Up and Start Again   \n",
      "15  Our Band Could Be Your Life: Scenes from the A...   \n",
      "16                                               Olio   \n",
      "17  Mesaerion: The Best Science Fiction Stories 18...   \n",
      "18                       Libertarianism for Beginners   \n",
      "19                            It's Only the Himalayas   \n",
      "\n",
      "                                                  url  \n",
      "0   http://books.toscrape.com/catalogue/a-light-in...  \n",
      "1   http://books.toscrape.com/catalogue/tipping-th...  \n",
      "2   http://books.toscrape.com/catalogue/soumission...  \n",
      "3   http://books.toscrape.com/catalogue/sharp-obje...  \n",
      "4   http://books.toscrape.com/catalogue/sapiens-a-...  \n",
      "5   http://books.toscrape.com/catalogue/the-requie...  \n",
      "6   http://books.toscrape.com/catalogue/the-dirty-...  \n",
      "7   http://books.toscrape.com/catalogue/the-coming...  \n",
      "8   http://books.toscrape.com/catalogue/the-boys-i...  \n",
      "9   http://books.toscrape.com/catalogue/the-black-...  \n",
      "10  http://books.toscrape.com/catalogue/starving-h...  \n",
      "11  http://books.toscrape.com/catalogue/shakespear...  \n",
      "12  http://books.toscrape.com/catalogue/set-me-fre...  \n",
      "13  http://books.toscrape.com/catalogue/scott-pilg...  \n",
      "14  http://books.toscrape.com/catalogue/rip-it-up-...  \n",
      "15  http://books.toscrape.com/catalogue/our-band-c...  \n",
      "16  http://books.toscrape.com/catalogue/olio_984/i...  \n",
      "17  http://books.toscrape.com/catalogue/mesaerion-...  \n",
      "18  http://books.toscrape.com/catalogue/libertaria...  \n",
      "19  http://books.toscrape.com/catalogue/its-only-t...  \n",
      "Data saved to extracted_books.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL to scrape\n",
    "url = 'http://books.toscrape.com'  # Change to 'http://example.com' if desired\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully retrieved the webpage.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extracting book titles and links\n",
    "books = soup.find_all('h3')\n",
    "data = []\n",
    "\n",
    "for book in books:\n",
    "    title = book.find('a').get('title')  # Extracting the title attribute\n",
    "    link = book.find('a').get('href')    # Extracting the href attribute\n",
    "    data.append({'title': title, 'url': f\"{url}/{link}\"})\n",
    "\n",
    "# Create a DataFrame with the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv('extracted_books.csv', index=False)\n",
    "print(\"Data saved to extracted_books.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
